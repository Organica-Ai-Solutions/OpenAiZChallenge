#!/usr/bin/env python3
"""
NIS Archaeological Discovery System - Main Backend
Comprehensive backend with all required endpoints
"""

import os
import sys
import asyncio
import json
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn
import logging
import requests
import base64
import random

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="NIS Archaeological Discovery System",
    description="Backend API for the Neural Intelligence System",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === DATA MODELS ===
class ArchaeologicalSite(BaseModel):
    id: str
    name: str
    coordinates: str
    confidence: float
    discovery_date: str
    cultural_significance: str
    data_sources: List[str]
    type: str
    period: str
    size_hectares: Optional[float] = None

class ChatMessage(BaseModel):
    message: str
    context: Optional[Dict[str, Any]] = None

class SatelliteRequest(BaseModel):
    lat: float
    lng: float
    zoom: Optional[int] = 15

# === MOCK DATA ===
ARCHAEOLOGICAL_SITES = [
    {
        "id": "site_001",
        "name": "Machu Picchu Archaeological Complex",
        "coordinates": "-13.1631, -72.5450",
        "confidence": 0.98,
        "discovery_date": "2024-01-15",
        "cultural_significance": "Inca royal estate with exceptional stone architecture and astronomical alignments",
        "data_sources": ["lidar", "satellite", "ground_survey"],
        "type": "ceremonial",
        "period": "Late Horizon (1400-1532 CE)",
        "size_hectares": 32.5
    },
    {
        "id": "site_002", 
        "name": "Chachapoya Settlement Complex",
        "coordinates": "-6.2084, -77.8717",
        "confidence": 0.85,
        "discovery_date": "2024-02-03",
        "cultural_significance": "Cloud forest settlement with unique circular architecture",
        "data_sources": ["satellite", "oral_histories", "botanical_survey"],
        "type": "settlement",
        "period": "Late Intermediate Period (1000-1470 CE)",
        "size_hectares": 18.7
    },
    {
        "id": "site_003",
        "name": "Nazca Ceremonial Center",
        "coordinates": "-14.7390, -75.1300",
        "confidence": 0.92,
        "discovery_date": "2024-01-28",
        "cultural_significance": "Desert ceremonial complex with geometric patterns and water management",
        "data_sources": ["satellite", "geophysical_survey", "ceramic_analysis"],
        "type": "ceremonial",
        "period": "Early Intermediate Period (200 BCE - 700 CE)",
        "size_hectares": 45.2
    },
    {
        "id": "site_004",
        "name": "Amazon Trade Hub",
        "coordinates": "-3.4653, -62.2159",
        "confidence": 0.78,
        "discovery_date": "2024-02-10",
        "cultural_significance": "Pre-Columbian trade center with evidence of long-distance exchange networks",
        "data_sources": ["lidar", "ethnographic_data", "artifact_analysis"],
        "type": "trade",
        "period": "Late Period (900-1532 CE)",
        "size_hectares": 12.3
    },
    {
        "id": "site_005",
        "name": "Highland Defensive Fortress",
        "coordinates": "-11.9404, -76.7648",
        "confidence": 0.89,
        "discovery_date": "2024-01-20",
        "cultural_significance": "Strategic mountain fortress with advanced defensive architecture",
        "data_sources": ["satellite", "topographic_analysis", "military_archaeology"],
        "type": "defensive",
        "period": "Late Intermediate Period (1000-1470 CE)",
        "size_hectares": 8.9
    }
]

AGENT_STATUS = {
    "agents": [
        {"id": "agent_001", "name": "LIDAR Analysis Agent", "status": "online", "accuracy": 0.94, "tasks_completed": 847},
        {"id": "agent_002", "name": "Satellite Imagery Agent", "status": "online", "accuracy": 0.91, "tasks_completed": 1203},
        {"id": "agent_003", "name": "Cultural Pattern Agent", "status": "online", "accuracy": 0.88, "tasks_completed": 592},
        {"id": "agent_004", "name": "Archaeological Context Agent", "status": "online", "accuracy": 0.96, "tasks_completed": 734},
        {"id": "agent_005", "name": "Discovery Synthesis Agent", "status": "online", "accuracy": 0.93, "tasks_completed": 456}
    ],
    "system_status": "healthy",
    "last_updated": datetime.now().isoformat()
}

# === HEALTH & STATUS ENDPOINTS ===
@app.get("/")
async def root():
    return {
        "status": "üèõÔ∏è NIS Archaeological Discovery System Online",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "active_agents": len([a for a in AGENT_STATUS["agents"] if a["status"] == "online"]),
        "total_sites": len(ARCHAEOLOGICAL_SITES)
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "api": "online",
            "database": "connected",
            "agents": "active",
            "satellite": "operational"
        }
    }

@app.get("/api/status")
async def api_status():
    return {
        "system": "NIS Archaeological Discovery System",
        "status": "operational",
        "agents": AGENT_STATUS["agents"],
        "system_health": AGENT_STATUS["system_status"],
        "uptime": "99.7%",
        "last_discovery": "2024-02-15T14:30:00Z"
    }

# === ARCHAEOLOGICAL SITES ENDPOINTS ===
@app.get("/api/sites")
async def get_archaeological_sites():
    """Get all archaeological sites"""
    return {
        "sites": ARCHAEOLOGICAL_SITES,
        "total": len(ARCHAEOLOGICAL_SITES),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/sites/{site_id}")
async def get_site_details(site_id: str):
    """Get details for a specific site"""
    site = next((s for s in ARCHAEOLOGICAL_SITES if s["id"] == site_id), None)
    if not site:
        raise HTTPException(status_code=404, detail="Site not found")
    return site

# === SATELLITE DATA ENDPOINTS ===
@app.get("/api/satellite/data")
async def get_satellite_data():
    """Get satellite system status and metadata"""
    return {
        "status": "operational",
        "satellites_active": 3,
        "coverage_area": "South America",
        "last_image_capture": "2024-02-15T12:00:00Z",
        "resolution": "0.6m/pixel",
        "data_sources": ["Landsat-8", "Sentinel-2", "SPOT-7"],
        "total_images": 15432,
        "archaeological_sites_monitored": len(ARCHAEOLOGICAL_SITES)
    }

@app.get("/satellite")
async def satellite_system_status():
    """Satellite system status endpoint"""
    return {
        "system": "satellite_monitoring",
        "status": "online",
        "active_satellites": 3,
        "data_quality": "excellent",
        "last_sync": datetime.now().isoformat()
    }

@app.post("/api/satellite/imagery")
async def request_satellite_imagery(request: SatelliteRequest):
    """Request satellite imagery for specific coordinates"""
    return {
        "request_id": f"sat_req_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "coordinates": {"lat": request.lat, "lng": request.lng},
        "zoom_level": request.zoom,
        "status": "processing",
        "estimated_completion": "2-3 minutes",
        "image_url": f"/api/satellite/image/{request.lat}/{request.lng}",
        "metadata": {
            "resolution": "0.6m/pixel",
            "capture_date": datetime.now().isoformat(),
            "cloud_cover": "5%"
        }
    }

@app.post("/api/satellite/analysis")
async def analyze_satellite_imagery(request: SatelliteRequest):
    """Analyze satellite imagery for archaeological features"""
    return {
        "analysis_id": f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "coordinates": {"lat": request.lat, "lng": request.lng},
        "features_detected": [
            {
                "type": "structural_anomaly",
                "confidence": 0.82,
                "coordinates": f"{request.lat + 0.001}, {request.lng + 0.001}",
                "size": "15m x 23m"
            },
            {
                "type": "geometric_pattern",
                "confidence": 0.67,
                "coordinates": f"{request.lat - 0.002}, {request.lng + 0.003}", 
                "description": "Possible ancient road system"
            }
        ],
        "analysis_complete": True,
        "processing_time": "1.3 seconds"
    }

# === AGENT & AI ENDPOINTS ===
@app.get("/api/agents")
async def get_agents():
    """Get all AI agents status"""
    return AGENT_STATUS

@app.post("/api/chat")
async def chat_with_agents(message: ChatMessage):
    """Chat with AI agents"""
    # Simulate intelligent response based on message content
    msg_lower = message.message.lower()
    
    if "eldorado" in msg_lower or "el dorado" in msg_lower:
        response = {
            "agent": "Discovery Synthesis Agent",
            "response": "üèõÔ∏è **El Dorado Analysis**: Based on our NIS protocol analysis, I've identified 3 promising locations that match historical descriptions of El Dorado. The Lake Guatavita region shows 89% correlation with Muisca ceremonial patterns, while our satellite data reveals geometric anomalies near Manoa coordinates that warrant immediate investigation.",
            "confidence": 0.89,
            "coordinates": ["-4.5361, -74.3644", "6.5000, -58.5000"],
            "next_actions": ["Deploy LIDAR survey", "Archaeological reconnaissance", "Cultural correlation analysis"]
        }
    elif "site" in msg_lower and "find" in msg_lower:
        response = {
            "agent": "Archaeological Context Agent", 
            "response": "üîç **Site Discovery Protocol**: I've analyzed your request and found 5 high-probability archaeological sites within your specified parameters. Confidence levels range from 78% to 98%. Would you like me to prioritize by cultural significance, accessibility, or discovery potential?",
            "confidence": 0.94,
            "sites_found": len(ARCHAEOLOGICAL_SITES),
            "recommendations": ["Start with highest confidence sites", "Consider seasonal accessibility", "Plan multi-site expedition"]
        }
    elif "analyze" in msg_lower:
        response = {
            "agent": "Cultural Pattern Agent",
            "response": "üìä **Pattern Analysis Complete**: I've identified significant cultural correlations across 847 data points. The analysis reveals three distinct cultural phases with 92% temporal accuracy. Geometric patterns suggest advanced mathematical knowledge, while material distributions indicate extensive trade networks.",
            "confidence": 0.92,
            "patterns_found": 23,
            "correlations": ["Temporal clustering", "Spatial distribution", "Cultural evolution"]
        }
    else:
        response = {
            "agent": "NIS Protocol Coordinator",
            "response": f"üß† **NIS Analysis**: I understand you're asking about '{message.message}'. Based on our archaeological database and AI analysis, I can provide insights on site discovery, cultural patterns, or expedition planning. What specific aspect would you like me to focus on?",
            "confidence": 0.87,
            "available_actions": ["Site analysis", "Route planning", "Cultural correlation", "Historical research"]
        }
    
    return {
        "message_id": f"msg_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "timestamp": datetime.now().isoformat(),
        **response
    }

# === DISCOVERY & ANALYSIS ENDPOINTS ===
@app.post("/api/analyze")
async def analyze_image():
    """Analyze uploaded images for archaeological features"""
    return {
        "analysis_id": f"img_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "status": "completed",
        "features_detected": [
            {
                "type": "stone_structure",
                "confidence": 0.91,
                "location": "center_region",
                "description": "Megalithic construction with precision-cut stones"
            },
            {
                "type": "terracing_system", 
                "confidence": 0.84,
                "location": "hillside_area",
                "description": "Ancient agricultural terraces"
            }
        ],
        "cultural_indicators": [
            {"indicator": "Inca-style stonework", "confidence": 0.88},
            {"indicator": "Ceremonial orientation", "confidence": 0.76}
        ],
        "recommendations": [
            "Ground-penetrating radar survey recommended",
            "Detailed photogrammetric documentation needed",
            "Carbon dating of associated organic materials"
        ]
    }

@app.get("/api/discoveries")
async def get_recent_discoveries():
    """Get recent archaeological discoveries"""
    return {
        "recent_discoveries": ARCHAEOLOGICAL_SITES[:3],
        "total_discoveries": len(ARCHAEOLOGICAL_SITES),
        "discovery_rate": "2.3 sites/month",
        "success_rate": "94.7%"
    }

# === VISION & IMAGE ANALYSIS ===
@app.post("/api/vision/analyze")
async def vision_analyze():
    """Vision analysis endpoint"""
    return {
        "analysis_id": f"vision_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "features": [
            {
                "type": "archaeological_structure",
                "confidence": 0.89,
                "bounds": {"x": 120, "y": 80, "width": 200, "height": 150},
                "description": "Possible stone foundation"
            }
        ],
        "metadata": {
            "processing_time": "0.8s",
            "model_version": "NIS-Vision-v2.1",
            "accuracy": "92.3%"
        }
    }

# === CODEX MODELS ===
class CodexDiscoveryRequest(BaseModel):
    coordinates: Dict[str, float]
    radius_km: int = 50
    period: str = "all"
    sources: List[str] = ["famsi", "world_digital_library", "inah"]
    max_results: int = 20

class CodexAnalysisRequest(BaseModel):
    codex_id: str
    image_url: str
    coordinates: Optional[Dict[str, float]] = None
    context: str = ""

class CodexDownloadRequest(BaseModel):
    codex_id: str
    download_type: str = "full"
    include_metadata: bool = True
    include_images: bool = True

# === REAL CODEX DATABASE ===
REAL_CODEX_DATABASE = [
    {
        "id": "codex_borgia_001",
        "title": "Codex Borgia",
        "source": "Vatican Library",
        "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Codex_Borgia_page_01.jpg/800px-Codex_Borgia_page_01.jpg",
        "period": "Pre-Columbian",
        "geographic_relevance": "Central Mexico",
        "relevance_score": 0.95,
        "content_type": "Ritual Calendar",
        "auto_extractable": True,
        "metadata": {
            "creation_date": "15th-16th century",
            "material": "Amatl paper",
            "pages": 76,
            "dimensions": "27 x 27 cm",
            "cultural_group": "Aztec/Mixtec",
            "archive": "Vatican Library",
            "digitization_quality": "high",
            "conservation_status": "excellent"
        }
    },
    {
        "id": "codex_mendoza_001", 
        "title": "Codex Mendoza",
        "source": "Bodleian Library, Oxford",
        "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Codex_Mendoza_folio_2r.jpg/800px-Codex_Mendoza_folio_2r.jpg",
        "period": "Colonial",
        "geographic_relevance": "Central Mexico",
        "relevance_score": 0.92,
        "content_type": "Historical Record",
        "auto_extractable": True,
        "metadata": {
            "creation_date": "1541",
            "material": "European paper",
            "pages": 71,
            "dimensions": "32 x 23 cm",
            "cultural_group": "Aztec",
            "archive": "Bodleian Library",
            "digitization_quality": "excellent",
            "conservation_status": "good"
        }
    },
    {
        "id": "codex_dresden_001",
        "title": "Dresden Codex",
        "source": "SLUB Dresden",
        "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Dresden_Codex_p09.jpg/800px-Dresden_Codex_p09.jpg",
        "period": "Pre-Columbian",
        "geographic_relevance": "Maya Region",
        "relevance_score": 0.88,
        "content_type": "Astronomical Calendar",
        "auto_extractable": True,
        "metadata": {
            "creation_date": "11th-12th century",
            "material": "Bark paper",
            "pages": 39,
            "dimensions": "20.5 x 9 cm",
            "cultural_group": "Maya",
            "archive": "SLUB Dresden",
            "digitization_quality": "high",
            "conservation_status": "fragile"
        }
    }
]

# === CODEX ENDPOINTS ===
@app.get("/api/codex/sources")
async def get_codex_sources():
    """Get available codex sources and their status"""
    return {
        "sources": [
            {"id": "famsi", "name": "Foundation for Ancient Mesoamerican Studies", "total_codices": 8, "status": "active"},
            {"id": "world_digital_library", "name": "World Digital Library", "total_codices": 12, "status": "active"},
            {"id": "inah", "name": "Instituto Nacional de Antropolog√≠a e Historia", "total_codices": 6, "status": "active"},
            {"id": "vatican_library", "name": "Vatican Library", "total_codices": 4, "status": "active"},
            {"id": "bodleian_library", "name": "Bodleian Library", "total_codices": 3, "status": "active"}
        ]
    }

@app.post("/api/codex/discover")
async def discover_codices(request: CodexDiscoveryRequest):
    """Discover relevant codices based on coordinates and parameters"""
    try:
        # Calculate geographic relevance based on coordinates
        lat, lng = request.coordinates["lat"], request.coordinates["lng"]
        
        # Filter codices based on relevance to coordinates
        relevant_codices = []
        for codex in REAL_CODEX_DATABASE:
            # Simple geographic relevance scoring
            geographic_match = 0.8  # Base relevance for all codices
            
            # Adjust for specific regions
            if "Maya" in codex["geographic_relevance"] and lat < 20 and lat > 10:
                geographic_match = 0.95
            elif "Central Mexico" in codex["geographic_relevance"] and lat > 15 and lat < 25:
                geographic_match = 0.9
            
            # Apply period filter
            if request.period != "all" and request.period.lower() not in codex["period"].lower():
                continue
                
            # Apply source filter
            codex_source = codex["metadata"]["archive"].lower().replace(" ", "_")
            if codex_source not in [s.lower() for s in request.sources]:
                continue
            
            # Create codex entry with updated relevance
            codex_entry = codex.copy()
            codex_entry["relevance_score"] = min(1.0, codex["relevance_score"] * geographic_match)
            codex_entry["distance_km"] = abs(lat - 19.4326) * 111  # Rough distance calculation
            relevant_codices.append(codex_entry)
        
        # Sort by relevance and limit results
        relevant_codices.sort(key=lambda x: x["relevance_score"], reverse=True)
        relevant_codices = relevant_codices[:request.max_results]
        
        return {
            "success": True,
            "total_found": len(relevant_codices),
            "codices": relevant_codices,
            "search_parameters": {
                "coordinates": request.coordinates,
                "radius_km": request.radius_km,
                "period": request.period,
                "sources": request.sources
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {"success": False, "error": str(e), "codices": []}

@app.post("/api/codex/analyze")
async def analyze_codex(request: CodexAnalysisRequest):
    """Analyze a codex using GPT-4 Vision"""
    try:
        # Find the codex in our database
        codex = next((c for c in REAL_CODEX_DATABASE if c["id"] == request.codex_id), None)
        if not codex:
            return {"success": False, "error": "Codex not found"}
        
        # Simulate GPT-4 Vision analysis
        analysis_result = {
            "visual_elements": {
                "glyphs_detected": random.randint(15, 45),
                "figures_identified": random.randint(3, 12),
                "color_palette": ["red ochre", "black carbon", "blue azurite", "yellow ochre"],
                "artistic_style": codex["metadata"]["cultural_group"] + " style",
                "preservation_quality": codex["metadata"]["conservation_status"]
            },
            "textual_content": {
                "script_type": "Pictographic" if "Maya" not in codex["geographic_relevance"] else "Hieroglyphic",
                "language_family": "Nahuatl" if "Aztec" in codex["metadata"]["cultural_group"] else "Maya",
                "readable_sections": random.randint(60, 85),
                "translation_confidence": random.uniform(0.7, 0.9)
            },
            "archaeological_insights": {
                "cultural_period": codex["period"],
                "geographic_origin": codex["geographic_relevance"],
                "ritual_significance": "High - contains calendar and ceremonial information",
                "historical_context": f"Important {codex['content_type'].lower()} from {codex['metadata']['creation_date']}",
                "research_value": "Extremely valuable for understanding pre-Columbian astronomy and ritual practices"
            },
            "coordinate_relevance": {
                "relevance_score": codex["relevance_score"],
                "geographic_match": "Strong correlation with requested coordinates",
                "cultural_connections": f"Relevant to {codex['geographic_relevance']} archaeological sites"
            },
            "recommendations": [
                {
                    "action": "cross_reference",
                    "description": "Cross-reference with nearby archaeological sites",
                    "priority": "high"
                },
                {
                    "action": "comparative_analysis", 
                    "description": "Compare with other codices from the same period",
                    "priority": "medium"
                },
                {
                    "action": "digital_preservation",
                    "description": "Ensure high-resolution digital preservation",
                    "priority": "high"
                }
            ],
            "metadata": {
                "analysis_model": "GPT-4 Vision",
                "confidence_score": random.uniform(0.75, 0.95),
                "processing_time": f"{random.uniform(2.5, 8.5):.1f}s",
                "analysis_timestamp": datetime.now().isoformat()
            }
        }
        
        return {
            "success": True,
            "codex_id": request.codex_id,
            "analysis": analysis_result,
            "confidence": analysis_result["metadata"]["confidence_score"]
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/codex/download")
async def download_codex(request: CodexDownloadRequest):
    """Download full codex data and metadata"""
    try:
        # Find the codex in our database
        codex = next((c for c in REAL_CODEX_DATABASE if c["id"] == request.codex_id), None)
        if not codex:
            return {"success": False, "error": "Codex not found"}
        
        download_data = {
            "codex_info": codex,
            "download_metadata": {
                "download_type": request.download_type,
                "timestamp": datetime.now().isoformat(),
                "file_format": "JSON",
                "include_metadata": request.include_metadata,
                "include_images": request.include_images
            }
        }
        
        if request.include_images:
            download_data["image_urls"] = [codex["image_url"]]
            download_data["image_metadata"] = {
                "primary_image": codex["image_url"],
                "resolution": "800px",
                "format": "JPEG",
                "source": codex["source"]
            }
        
        if request.include_metadata:
            download_data["extended_metadata"] = {
                "bibliographic_info": {
                    "title": codex["title"],
                    "source_institution": codex["source"],
                    "creation_period": codex["metadata"]["creation_date"],
                    "cultural_attribution": codex["metadata"]["cultural_group"]
                },
                "physical_description": {
                    "material": codex["metadata"]["material"],
                    "dimensions": codex["metadata"]["dimensions"], 
                    "page_count": codex["metadata"]["pages"],
                    "conservation_status": codex["metadata"]["conservation_status"]
                },
                "digital_info": {
                    "digitization_quality": codex["metadata"]["digitization_quality"],
                    "archive_location": codex["metadata"]["archive"]
                }
            }
        
        return {
            "success": True, 
            "download_data": download_data,
            "file_size_estimate": "2.5MB",
            "recommended_filename": f"{codex['title'].replace(' ', '_').lower()}_complete.json"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

# === ERROR HANDLERS ===
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Endpoint not found",
            "message": f"The requested endpoint was not found",
            "available_endpoints": [
                "/api/sites", "/api/agents", "/api/chat", "/api/analyze",
                "/api/satellite/data", "/api/vision/analyze", "/health"
            ]
        }
    )

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"Internal server error: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "An unexpected error occurred",
            "timestamp": datetime.now().isoformat()
        }
    )

# === STARTUP ===
if __name__ == "__main__":
    print("üèõÔ∏è Starting NIS Archaeological Discovery System...")
    print("üì° All endpoints operational")
    print("ü§ñ AI agents online")
    print("üõ∞Ô∏è Satellite systems connected")
    print("üöÄ Backend ready at http://localhost:8000")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        reload=True
    ) 