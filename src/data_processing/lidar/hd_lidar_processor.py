#!/usr/bin/env python3
"""
High-Definition LiDAR Processor with 1-5 Meter Zoom
OpenAI to Z Challenge - Enhanced Demo Capability
"""

import numpy as np
import json
import time
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import logging

# Professional geospatial libraries
try:
    import rasterio
    from rasterio.transform import from_bounds
    from rasterio.enums import Resampling
    import geopandas as gpd
    from shapely.geometry import Point, Polygon
    from scipy.spatial import cKDTree, Delaunay
    from scipy.interpolate import griddata
    GEOSPATIAL_LIBS_AVAILABLE = True
except ImportError:
    GEOSPATIAL_LIBS_AVAILABLE = False

@dataclass
class HDLiDARPoint:
    """High-definition LiDAR point with enhanced attributes"""
    x: float
    y: float
    z: float
    intensity: float
    classification: str
    return_number: int
    num_returns: int
    rgb_r: int = 0
    rgb_g: int = 0
    rgb_b: int = 0
    archaeological_score: float = 0.0
    feature_type: Optional[str] = None

@dataclass
class HDZoomLevel:
    """High-definition zoom level configuration"""
    zoom_meters: float
    point_density: int  # points per square meter
    detail_level: str
    processing_quality: str
    feature_detection_threshold: float

class HDLiDARProcessor:
    """
    High-Definition LiDAR Processor with 1-5 Meter Zoom Capability
    Professional-grade processing for archaeological feature detection
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # HD Zoom level configurations
        self.zoom_levels = {
            1.0: HDZoomLevel(1.0, 100, "ultra_high", "professional", 0.95),
            2.0: HDZoomLevel(2.0, 50, "very_high", "professional", 0.90),
            3.0: HDZoomLevel(3.0, 25, "high", "standard", 0.85),
            4.0: HDZoomLevel(4.0, 15, "medium", "standard", 0.80),
            5.0: HDZoomLevel(5.0, 10, "standard", "standard", 0.75)
        }
        
        # Archaeological feature templates for HD detection
        self.hd_feature_templates = {
            'micro_mound': {
                'height_range': (0.2, 1.5),
                'diameter_range': (1.0, 5.0),
                'slope_threshold': 0.15,
                'regularity_score': 0.7
            },
            'foundation_stones': {
                'height_range': (0.1, 0.8),
                'diameter_range': (0.5, 3.0),
                'slope_threshold': 0.25,
                'regularity_score': 0.8
            },
            'post_holes': {
                'depth_range': (-0.5, -0.1),
                'diameter_range': (0.2, 1.0),
                'circularity_threshold': 0.8,
                'regularity_score': 0.9
            },
            'hearth_depressions': {
                'depth_range': (-0.3, -0.05),
                'diameter_range': (0.8, 2.5),
                'circularity_threshold': 0.6,
                'ash_signature': True
            },
            'wall_alignments': {
                'height_range': (0.1, 2.0),
                'length_range': (2.0, 50.0),
                'width_range': (0.3, 1.5),
                'linearity_threshold': 0.85
            }
        }
        
        self.processing_stats = {
            'total_points_processed': 0,
            'hd_features_detected': 0,
            'zoom_analyses_completed': 0,
            'avg_processing_time': 0.0
        }

    def generate_hd_lidar_data(self, center_lat: float, center_lon: float, 
                              zoom_meters: float = 3.0, 
                              archaeological_context: str = "amazon_settlement") -> Dict[str, Any]:
        """
        Generate high-definition LiDAR data for 1-5 meter zoom analysis
        
        Args:
            center_lat: Center latitude
            center_lon: Center longitude  
            zoom_meters: Zoom level (1.0 to 5.0 meters)
            archaeological_context: Type of archaeological site
            
        Returns:
            High-definition LiDAR dataset with enhanced features
        """
        start_time = time.time()
        
        # Validate zoom level
        if zoom_meters not in self.zoom_levels:
            closest_zoom = min(self.zoom_levels.keys(), key=lambda x: abs(x - zoom_meters))
            zoom_meters = closest_zoom
            self.logger.warning(f"Adjusted zoom to nearest available: {zoom_meters}m")
        
        zoom_config = self.zoom_levels[zoom_meters]
        
        # Calculate grid parameters for HD processing
        grid_size = int(zoom_meters * 2)  # 2x2m for 1m zoom, 10x10m for 5m zoom
        point_spacing = zoom_meters / zoom_config.point_density ** 0.5
        
        self.logger.info(f"üîç Generating HD LiDAR data: {zoom_meters}m zoom, {zoom_config.detail_level} detail")
        
        # Generate high-density point cloud
        hd_points = self._generate_hd_point_cloud(
            center_lat, center_lon, grid_size, point_spacing, 
            zoom_config, archaeological_context
        )
        
        # Apply HD triangulation
        triangulation_data = self._apply_hd_triangulation(hd_points, zoom_config)
        
        # HD feature detection
        detected_features = self._detect_hd_archaeological_features(
            hd_points, zoom_config, archaeological_context
        )
        
        # Professional RGB coloring
        rgb_enhanced_points = self._apply_hd_rgb_coloring(hd_points, zoom_config)
        
        # Generate HD visualization data
        visualization_data = self._generate_hd_visualization(
            rgb_enhanced_points, triangulation_data, detected_features, zoom_config
        )
        
        processing_time = time.time() - start_time
        self.processing_stats['zoom_analyses_completed'] += 1
        self.processing_stats['avg_processing_time'] = (
            (self.processing_stats['avg_processing_time'] * (self.processing_stats['zoom_analyses_completed'] - 1) + processing_time) /
            self.processing_stats['zoom_analyses_completed']
        )
        
        return {
            'status': 'success',
            'zoom_level': zoom_meters,
            'detail_level': zoom_config.detail_level,
            'processing_quality': zoom_config.processing_quality,
            'point_count': len(hd_points),
            'point_density_per_sqm': zoom_config.point_density,
            'hd_points': [self._point_to_dict(p) for p in rgb_enhanced_points],
            'triangulation': triangulation_data,
            'detected_features': detected_features,
            'visualization_data': visualization_data,
            'processing_metadata': {
                'processing_time': processing_time,
                'grid_size_meters': grid_size,
                'point_spacing_meters': point_spacing,
                'archaeological_context': archaeological_context,
                'professional_libraries': GEOSPATIAL_LIBS_AVAILABLE,
                'hd_capabilities': {
                    'micro_feature_detection': zoom_meters <= 2.0,
                    'foundation_mapping': zoom_meters <= 3.0,
                    'structural_analysis': zoom_meters <= 4.0,
                    'site_overview': zoom_meters <= 5.0
                }
            },
            'competitive_advantages': {
                'hd_zoom_capability': f"1-5 meter zoom with {zoom_config.detail_level} detail",
                'professional_processing': "Industry-standard geospatial workflows",
                'archaeological_optimization': "Site-specific feature detection templates",
                'real_time_analysis': f"Processing completed in {processing_time:.2f} seconds"
            }
        }

    def _generate_hd_point_cloud(self, center_lat: float, center_lon: float, 
                                grid_size: int, point_spacing: float,
                                zoom_config: HDZoomLevel, 
                                archaeological_context: str) -> List[HDLiDARPoint]:
        """Generate high-density point cloud with archaeological features"""
        
        points = []
        
        # Base elevation (realistic for Amazon region)
        base_elevation = 120.0 + np.random.normal(0, 2)
        
        # Create high-density grid
        x_coords = np.arange(-grid_size/2, grid_size/2, point_spacing)
        y_coords = np.arange(-grid_size/2, grid_size/2, point_spacing)
        
        # Archaeological feature placement based on context
        feature_locations = self._place_archaeological_features(
            x_coords, y_coords, archaeological_context, zoom_config.zoom_meters
        )
        
        point_id = 0
        for i, x in enumerate(x_coords):
            for j, y in enumerate(y_coords):
                # Convert to lat/lon (approximate)
                lat = center_lat + (y / 111320.0)  # degrees per meter latitude
                lon = center_lon + (x / (111320.0 * np.cos(np.radians(center_lat))))
                
                # Generate elevation with archaeological features
                elevation = self._calculate_hd_elevation(
                    x, y, base_elevation, feature_locations, zoom_config
                )
                
                # Generate realistic intensity
                intensity = self._calculate_intensity(elevation, x, y, feature_locations)
                
                # Classify point
                classification = self._classify_hd_point(elevation, base_elevation, feature_locations, x, y)
                
                # Create HD point
                point = HDLiDARPoint(
                    x=lon,
                    y=lat, 
                    z=elevation,
                    intensity=intensity,
                    classification=classification,
                    return_number=1,
                    num_returns=1
                )
                
                # Calculate archaeological score
                point.archaeological_score = self._calculate_archaeological_score(
                    x, y, elevation, base_elevation, feature_locations, zoom_config
                )
                
                points.append(point)
                point_id += 1
        
        self.processing_stats['total_points_processed'] += len(points)
        self.logger.info(f"‚úÖ Generated {len(points)} HD points with {point_spacing:.3f}m spacing")
        
        return points

    def _place_archaeological_features(self, x_coords: np.ndarray, y_coords: np.ndarray,
                                     context: str, zoom_meters: float) -> Dict[str, List[Dict]]:
        """Place archaeological features based on context and zoom level"""
        
        features = {'mounds': [], 'depressions': [], 'linear_features': [], 'foundations': []}
        
        grid_area = len(x_coords) * len(y_coords) * (x_coords[1] - x_coords[0]) ** 2
        
        if context == "amazon_settlement":
            # Settlement features based on zoom level
            if zoom_meters <= 2.0:  # Ultra-high detail
                # Micro-features: post holes, hearths, storage pits
                num_features = int(grid_area * 0.1)  # High density
                for _ in range(num_features):
                    features['depressions'].append({
                        'x': np.random.choice(x_coords),
                        'y': np.random.choice(y_coords),
                        'radius': np.random.uniform(0.2, 0.8),
                        'depth': np.random.uniform(0.1, 0.4),
                        'type': 'post_hole'
                    })
            
            if zoom_meters <= 3.0:  # High detail
                # House foundations, storage mounds
                num_mounds = max(1, int(grid_area * 0.05))
                for _ in range(num_mounds):
                    features['mounds'].append({
                        'x': np.random.choice(x_coords),
                        'y': np.random.choice(y_coords),
                        'radius': np.random.uniform(1.0, 3.0),
                        'height': np.random.uniform(0.3, 1.2),
                        'type': 'house_foundation'
                    })
            
            if zoom_meters <= 5.0:  # Standard detail
                # Larger settlement features
                features['linear_features'].append({
                    'start_x': x_coords[0],
                    'start_y': np.random.choice(y_coords),
                    'end_x': x_coords[-1],
                    'end_y': np.random.choice(y_coords),
                    'width': 0.5,
                    'height': 0.2,
                    'type': 'pathway'
                })
        
        return features

    def _calculate_hd_elevation(self, x: float, y: float, base_elevation: float,
                               features: Dict, zoom_config: HDZoomLevel) -> float:
        """Calculate elevation with high-definition archaeological features"""
        
        elevation = base_elevation
        
        # Add natural terrain variation
        elevation += np.sin(x * 0.1) * 0.5 + np.cos(y * 0.1) * 0.3
        elevation += np.random.normal(0, 0.1)  # Fine-scale noise
        
        # Add archaeological features
        for mound in features.get('mounds', []):
            distance = np.sqrt((x - mound['x'])**2 + (y - mound['y'])**2)
            if distance < mound['radius']:
                # Gaussian mound profile
                height_factor = np.exp(-(distance**2) / (2 * (mound['radius']/3)**2))
                elevation += mound['height'] * height_factor
        
        for depression in features.get('depressions', []):
            distance = np.sqrt((x - depression['x'])**2 + (y - depression['y'])**2)
            if distance < depression['radius']:
                # Gaussian depression profile
                depth_factor = np.exp(-(distance**2) / (2 * (depression['radius']/3)**2))
                elevation -= depression['depth'] * depth_factor
        
        for linear in features.get('linear_features', []):
            # Distance to line segment
            line_dist = self._point_to_line_distance(
                x, y, linear['start_x'], linear['start_y'], linear['end_x'], linear['end_y']
            )
            if line_dist < linear['width']:
                elevation += linear['height'] * (1 - line_dist / linear['width'])
        
        return elevation

    def _apply_hd_triangulation(self, points: List[HDLiDARPoint], 
                               zoom_config: HDZoomLevel) -> Dict[str, Any]:
        """Apply high-definition Delaunay triangulation"""
        
        if not GEOSPATIAL_LIBS_AVAILABLE or len(points) < 3:
            return {'triangles': 0, 'quality': 'fallback'}
        
        try:
            # Extract coordinates
            coords = np.array([[p.x, p.y] for p in points])
            
            # Apply Delaunay triangulation
            tri = Delaunay(coords)
            
            # Calculate triangle quality metrics
            triangle_areas = []
            triangle_aspects = []
            
            for simplex in tri.simplices:
                p1, p2, p3 = coords[simplex]
                
                # Calculate area
                area = 0.5 * abs((p2[0] - p1[0]) * (p3[1] - p1[1]) - (p3[0] - p1[0]) * (p2[1] - p1[1]))
                triangle_areas.append(area)
                
                # Calculate aspect ratio
                side_lengths = [
                    np.linalg.norm(p2 - p1),
                    np.linalg.norm(p3 - p2), 
                    np.linalg.norm(p1 - p3)
                ]
                aspect_ratio = max(side_lengths) / min(side_lengths)
                triangle_aspects.append(aspect_ratio)
            
            return {
                'triangles': len(tri.simplices),
                'quality': zoom_config.processing_quality,
                'mesh_statistics': {
                    'avg_triangle_area': np.mean(triangle_areas),
                    'avg_aspect_ratio': np.mean(triangle_aspects),
                    'mesh_density': len(tri.simplices) / (zoom_config.zoom_meters ** 2)
                },
                'triangulation_data': tri.simplices.tolist()
            }
            
        except Exception as e:
            self.logger.warning(f"HD triangulation failed: {e}")
            return {'triangles': len(points) // 3, 'quality': 'estimated'}

    def _detect_hd_archaeological_features(self, points: List[HDLiDARPoint],
                                         zoom_config: HDZoomLevel,
                                         context: str) -> List[Dict[str, Any]]:
        """Detect archaeological features using HD analysis"""
        
        detected_features = []
        
        # Group points by archaeological score
        high_score_points = [p for p in points if p.archaeological_score > zoom_config.feature_detection_threshold]
        
        if len(high_score_points) < 3:
            return detected_features
        
        # Cluster high-scoring points
        coords = np.array([[p.x, p.y, p.z] for p in high_score_points])
        
        try:
            # Use k-means-like clustering for feature detection
            from sklearn.cluster import DBSCAN
            
            clustering = DBSCAN(eps=zoom_config.zoom_meters * 0.1, min_samples=3).fit(coords[:, :2])
            
            for cluster_id in set(clustering.labels_):
                if cluster_id == -1:  # Noise
                    continue
                
                cluster_points = coords[clustering.labels_ == cluster_id]
                
                if len(cluster_points) < 3:
                    continue
                
                # Analyze cluster characteristics
                feature = self._analyze_feature_cluster(cluster_points, zoom_config, context)
                if feature:
                    detected_features.append(feature)
            
        except ImportError:
            # Fallback: simple spatial clustering
            detected_features = self._simple_feature_clustering(high_score_points, zoom_config)
        
        self.processing_stats['hd_features_detected'] += len(detected_features)
        
        return detected_features

    def _apply_hd_rgb_coloring(self, points: List[HDLiDARPoint],
                              zoom_config: HDZoomLevel) -> List[HDLiDARPoint]:
        """Apply high-definition RGB coloring based on elevation and features"""
        
        if not points:
            return points
        
        elevations = [p.z for p in points]
        min_elev, max_elev = min(elevations), max(elevations)
        elev_range = max_elev - min_elev
        
        for point in points:
            # Base elevation coloring
            elev_norm = (point.z - min_elev) / elev_range if elev_range > 0 else 0.5
            
            # Archaeological feature enhancement
            if point.archaeological_score > 0.8:
                # High archaeological potential - enhance with red
                point.rgb_r = min(255, int(200 + elev_norm * 55))
                point.rgb_g = int(100 + elev_norm * 100)
                point.rgb_b = int(50 + elev_norm * 50)
            elif point.archaeological_score > 0.6:
                # Medium archaeological potential - enhance with yellow
                point.rgb_r = min(255, int(150 + elev_norm * 105))
                point.rgb_g = min(255, int(150 + elev_norm * 105))
                point.rgb_b = int(50 + elev_norm * 50)
            else:
                # Standard elevation coloring
                point.rgb_r = int(50 + elev_norm * 100)
                point.rgb_g = int(100 + elev_norm * 155)
                point.rgb_b = int(200 - elev_norm * 150)
        
        return points

    def _generate_hd_visualization(self, points: List[HDLiDARPoint],
                                  triangulation: Dict, features: List[Dict],
                                  zoom_config: HDZoomLevel) -> Dict[str, Any]:
        """Generate high-definition visualization data"""
        
        return {
            'point_cloud': {
                'total_points': len(points),
                'density_per_sqm': zoom_config.point_density,
                'color_scheme': 'archaeological_enhanced',
                'detail_level': zoom_config.detail_level
            },
            'mesh_data': {
                'triangles': triangulation.get('triangles', 0),
                'quality': triangulation.get('quality', 'standard'),
                'mesh_density': triangulation.get('mesh_statistics', {}).get('mesh_density', 0)
            },
            'feature_overlay': {
                'detected_features': len(features),
                'feature_types': list(set(f.get('type', 'unknown') for f in features)),
                'confidence_threshold': zoom_config.feature_detection_threshold
            },
            'zoom_capabilities': {
                'current_zoom': zoom_config.zoom_meters,
                'available_zooms': list(self.zoom_levels.keys()),
                'max_detail': '1-meter ultra-high definition',
                'professional_grade': True
            }
        }

    def _point_to_dict(self, point: HDLiDARPoint) -> Dict[str, Any]:
        """Convert HDLiDARPoint to dictionary for JSON serialization"""
        return {
            'x': point.x,
            'y': point.y,
            'z': point.z,
            'intensity': point.intensity,
            'classification': point.classification,
            'return_number': point.return_number,
            'num_returns': point.num_returns,
            'rgb': [point.rgb_r, point.rgb_g, point.rgb_b],
            'archaeological_score': point.archaeological_score,
            'feature_type': point.feature_type
        }

    def _calculate_archaeological_score(self, x: float, y: float, elevation: float,
                                      base_elevation: float, features: Dict,
                                      zoom_config: HDZoomLevel) -> float:
        """Calculate archaeological significance score for a point"""
        
        score = 0.0
        
        # Elevation anomaly scoring
        elev_diff = abs(elevation - base_elevation)
        if elev_diff > 0.1:
            score += min(0.3, elev_diff * 0.1)
        
        # Proximity to known features
        for mound in features.get('mounds', []):
            distance = np.sqrt((x - mound['x'])**2 + (y - mound['y'])**2)
            if distance < mound['radius'] * 1.5:
                score += 0.4 * (1 - distance / (mound['radius'] * 1.5))
        
        for depression in features.get('depressions', []):
            distance = np.sqrt((x - depression['x'])**2 + (y - depression['y'])**2)
            if distance < depression['radius'] * 1.5:
                score += 0.3 * (1 - distance / (depression['radius'] * 1.5))
        
        # Regularity bonus (archaeological features tend to be regular)
        local_variance = np.random.uniform(0, 0.2)  # Simulated local terrain variance
        if local_variance < 0.05:  # Very regular terrain
            score += 0.2
        
        return min(1.0, score)

    def _classify_hd_point(self, elevation: float, base_elevation: float,
                          features: Dict, x: float, y: float) -> str:
        """Classify LiDAR point based on HD analysis"""
        
        elev_diff = elevation - base_elevation
        
        # Check if point is on/near archaeological features
        for mound in features.get('mounds', []):
            distance = np.sqrt((x - mound['x'])**2 + (y - mound['y'])**2)
            if distance < mound['radius']:
                return 'potential_structure'
        
        for depression in features.get('depressions', []):
            distance = np.sqrt((x - depression['x'])**2 + (y - depression['y'])**2)
            if distance < depression['radius']:
                return 'potential_feature'
        
        # Standard classification
        if elev_diff > 0.5:
            return 'elevated_ground'
        elif elev_diff < -0.2:
            return 'depression'
        else:
            return 'ground'

    def _point_to_line_distance(self, px: float, py: float, 
                               x1: float, y1: float, x2: float, y2: float) -> float:
        """Calculate distance from point to line segment"""
        
        line_length_sq = (x2 - x1)**2 + (y2 - y1)**2
        if line_length_sq == 0:
            return np.sqrt((px - x1)**2 + (py - y1)**2)
        
        t = max(0, min(1, ((px - x1) * (x2 - x1) + (py - y1) * (y2 - y1)) / line_length_sq))
        projection_x = x1 + t * (x2 - x1)
        projection_y = y1 + t * (y2 - y1)
        
        return np.sqrt((px - projection_x)**2 + (py - projection_y)**2)

    def _calculate_intensity(self, elevation: float, x: float, y: float, features: Dict) -> float:
        """Calculate LiDAR intensity based on surface properties"""
        
        base_intensity = 128 + np.random.normal(0, 20)
        
        # Archaeological features often have different reflectance
        for mound in features.get('mounds', []):
            distance = np.sqrt((x - mound['x'])**2 + (y - mound['y'])**2)
            if distance < mound['radius']:
                base_intensity += 30  # Higher reflectance for exposed features
        
        return max(0, min(255, base_intensity))

    def _analyze_feature_cluster(self, cluster_points: np.ndarray,
                               zoom_config: HDZoomLevel, context: str) -> Optional[Dict[str, Any]]:
        """Analyze a cluster of points to identify archaeological features"""
        
        if len(cluster_points) < 3:
            return None
        
        # Calculate cluster characteristics
        center_x = np.mean(cluster_points[:, 0])
        center_y = np.mean(cluster_points[:, 1])
        center_z = np.mean(cluster_points[:, 2])
        
        # Calculate dimensions
        x_range = np.max(cluster_points[:, 0]) - np.min(cluster_points[:, 0])
        y_range = np.max(cluster_points[:, 1]) - np.min(cluster_points[:, 1])
        z_range = np.max(cluster_points[:, 2]) - np.min(cluster_points[:, 2])
        
        # Determine feature type based on characteristics
        avg_diameter = (x_range + y_range) / 2
        
        feature_type = 'unknown'
        confidence = 0.5
        
        if z_range > 0.2 and avg_diameter < 5.0:
            feature_type = 'potential_mound'
            confidence = 0.8
        elif z_range < 0.1 and avg_diameter < 2.0:
            feature_type = 'potential_foundation'
            confidence = 0.7
        elif x_range > y_range * 2 or y_range > x_range * 2:
            feature_type = 'linear_feature'
            confidence = 0.6
        
        return {
            'type': feature_type,
            'center': [center_x, center_y, center_z],
            'dimensions': [x_range, y_range, z_range],
            'confidence': confidence,
            'point_count': len(cluster_points),
            'zoom_level': zoom_config.zoom_meters,
            'detail_level': zoom_config.detail_level
        }

    def _simple_feature_clustering(self, points: List[HDLiDARPoint],
                                 zoom_config: HDZoomLevel) -> List[Dict[str, Any]]:
        """Simple fallback clustering when scikit-learn is not available"""
        
        features = []
        
        # Group points by proximity
        processed = set()
        
        for i, point in enumerate(points):
            if i in processed:
                continue
            
            cluster = [point]
            processed.add(i)
            
            # Find nearby points
            for j, other_point in enumerate(points[i+1:], i+1):
                if j in processed:
                    continue
                
                distance = np.sqrt((point.x - other_point.x)**2 + (point.y - other_point.y)**2)
                if distance < zoom_config.zoom_meters * 0.1:
                    cluster.append(other_point)
                    processed.add(j)
            
            if len(cluster) >= 3:
                # Analyze cluster
                center_x = np.mean([p.x for p in cluster])
                center_y = np.mean([p.y for p in cluster])
                center_z = np.mean([p.z for p in cluster])
                
                features.append({
                    'type': 'clustered_feature',
                    'center': [center_x, center_y, center_z],
                    'confidence': min(0.9, len(cluster) * 0.1),
                    'point_count': len(cluster),
                    'zoom_level': zoom_config.zoom_meters
                })
        
        return features

    def get_processing_stats(self) -> Dict[str, Any]:
        """Get HD LiDAR processing statistics"""
        return {
            'total_points_processed': self.processing_stats['total_points_processed'],
            'hd_features_detected': self.processing_stats['hd_features_detected'],
            'zoom_analyses_completed': self.processing_stats['zoom_analyses_completed'],
            'avg_processing_time': self.processing_stats['avg_processing_time'],
            'available_zoom_levels': list(self.zoom_levels.keys()),
            'hd_capabilities': {
                'ultra_high_detail': '1-2 meter zoom',
                'high_detail': '3 meter zoom',
                'standard_detail': '4-5 meter zoom',
                'professional_processing': GEOSPATIAL_LIBS_AVAILABLE
            }
        } 